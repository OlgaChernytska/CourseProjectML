{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project\n",
    "Author: Olga Chernytska\n",
    " \n",
    "## Part 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0. Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(direction):\n",
    "    df = pd.read_csv('output/direction'+str(direction) + '_df_clean.csv')\n",
    "    df = df[['drive_index','start_stop','end_stop','start_time','time_diff_seconds']]\n",
    "    df['start_time'] = pd.to_datetime(df['start_time'], unit='ns')\n",
    "    df['direction'] = direction\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction0_df = load_data(0)\n",
    "direction1_df = load_data(1)\n",
    "\n",
    "df_step0 = pd.concat([direction0_df, direction1_df])\n",
    "df_step0 = df_step0.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "(150864, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drive_index</th>\n",
       "      <th>start_stop</th>\n",
       "      <th>end_stop</th>\n",
       "      <th>start_time</th>\n",
       "      <th>time_diff_seconds</th>\n",
       "      <th>direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>stop #01: id=36853</td>\n",
       "      <td>stop #02: id=37283</td>\n",
       "      <td>2017-07-20 06:29:53.937044000</td>\n",
       "      <td>30.763969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>stop #02: id=37283</td>\n",
       "      <td>stop #03: id=36822</td>\n",
       "      <td>2017-07-20 06:30:24.701013000</td>\n",
       "      <td>195.895895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>stop #03: id=36822</td>\n",
       "      <td>stop #04: id=36823</td>\n",
       "      <td>2017-07-20 06:33:40.596908000</td>\n",
       "      <td>97.629325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>stop #04: id=36823</td>\n",
       "      <td>stop #05: id=36821</td>\n",
       "      <td>2017-07-20 06:35:18.226233500</td>\n",
       "      <td>31.148851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>stop #05: id=36821</td>\n",
       "      <td>stop #06: id=36812</td>\n",
       "      <td>2017-07-20 06:35:49.375084000</td>\n",
       "      <td>158.963154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   drive_index          start_stop            end_stop  \\\n",
       "0            8  stop #01: id=36853  stop #02: id=37283   \n",
       "1            8  stop #02: id=37283  stop #03: id=36822   \n",
       "2            8  stop #03: id=36822  stop #04: id=36823   \n",
       "3            8  stop #04: id=36823  stop #05: id=36821   \n",
       "4            8  stop #05: id=36821  stop #06: id=36812   \n",
       "\n",
       "                     start_time  time_diff_seconds  direction  \n",
       "0 2017-07-20 06:29:53.937044000          30.763969          0  \n",
       "1 2017-07-20 06:30:24.701013000         195.895895          0  \n",
       "2 2017-07-20 06:33:40.596908000          97.629325          0  \n",
       "3 2017-07-20 06:35:18.226233500          31.148851          0  \n",
       "4 2017-07-20 06:35:49.375084000         158.963154          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Result: ')\n",
    "print(df_step0.shape)\n",
    "df_step0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Add features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df['season'] = np.where(df['start_time'].dt.month.isin([12,1,2]), 'winter',\n",
    "                             np.where(df['start_time'].dt.month.isin([3,4,5]), 'spring',\n",
    "                             np.where(df['start_time'].dt.month.isin([6,7,8]), 'summer', 'autumn')))\n",
    "    df['weekday'] = df['start_time'].dt.weekday_name\n",
    "    df['hour'] = df['start_time'].dt.hour\n",
    "    df['minute'] = (round(df['start_time'].dt.minute/15,0)*15 % 60).astype(int)\n",
    "    df['route_interval'] = df['start_stop'].str.extract('(#\\d*)', expand = False) + '_' \\\n",
    "                        + df['end_stop'].str.extract('(#\\d*)', expand = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_step1 = add_features(df_step0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange to dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_with_dummies(df):\n",
    "    dummies_direction = pd.get_dummies(df['direction'], drop_first = True, prefix = 'is_direction')\n",
    "    dummies_route_stops = pd.get_dummies(df['route_interval'], drop_first = True, prefix = 'is_stops')\n",
    "\n",
    "    dummies_season = pd.get_dummies(df['season'], drop_first = True, prefix='is')\n",
    "    dummies_weekday = pd.get_dummies(df['weekday'], drop_first = True, prefix = 'is')\n",
    "    dummies_hour = pd.get_dummies(df['hour'], drop_first = True, prefix = 'is_hour')\n",
    "    dummies_minute = pd.get_dummies(df['minute'], drop_first = True, prefix = 'is_minute')\n",
    "    \n",
    "    return df[['time_diff_seconds']].join([dummies_direction, dummies_route_stops,\n",
    "                                      dummies_season, dummies_weekday, dummies_hour, dummies_minute] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_step1_dummies = df_with_dummies(df_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "(150864, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_diff_seconds</th>\n",
       "      <th>is_direction_1</th>\n",
       "      <th>is_stops_#01_#02</th>\n",
       "      <th>is_stops_#02_#03</th>\n",
       "      <th>is_stops_#03_#04</th>\n",
       "      <th>is_stops_#04_#05</th>\n",
       "      <th>is_stops_#05_#06</th>\n",
       "      <th>is_stops_#06_#07</th>\n",
       "      <th>is_stops_#07_#08</th>\n",
       "      <th>is_stops_#08_#09</th>\n",
       "      <th>...</th>\n",
       "      <th>is_hour_13</th>\n",
       "      <th>is_hour_14</th>\n",
       "      <th>is_hour_15</th>\n",
       "      <th>is_hour_16</th>\n",
       "      <th>is_hour_17</th>\n",
       "      <th>is_hour_18</th>\n",
       "      <th>is_hour_19</th>\n",
       "      <th>is_minute_15</th>\n",
       "      <th>is_minute_30</th>\n",
       "      <th>is_minute_45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.763969</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195.895895</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.629325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.148851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158.963154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_diff_seconds  is_direction_1  is_stops_#01_#02  is_stops_#02_#03  \\\n",
       "0          30.763969               0                 1                 0   \n",
       "1         195.895895               0                 0                 1   \n",
       "2          97.629325               0                 0                 0   \n",
       "3          31.148851               0                 0                 0   \n",
       "4         158.963154               0                 0                 0   \n",
       "\n",
       "   is_stops_#03_#04  is_stops_#04_#05  is_stops_#05_#06  is_stops_#06_#07  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 1                 0                 0                 0   \n",
       "3                 0                 1                 0                 0   \n",
       "4                 0                 0                 1                 0   \n",
       "\n",
       "   is_stops_#07_#08  is_stops_#08_#09      ...       is_hour_13  is_hour_14  \\\n",
       "0                 0                 0      ...                0           0   \n",
       "1                 0                 0      ...                0           0   \n",
       "2                 0                 0      ...                0           0   \n",
       "3                 0                 0      ...                0           0   \n",
       "4                 0                 0      ...                0           0   \n",
       "\n",
       "   is_hour_15  is_hour_16  is_hour_17  is_hour_18  is_hour_19  is_minute_15  \\\n",
       "0           0           0           0           0           0             0   \n",
       "1           0           0           0           0           0             0   \n",
       "2           0           0           0           0           0             0   \n",
       "3           0           0           0           0           0             0   \n",
       "4           0           0           0           0           0             0   \n",
       "\n",
       "   is_minute_30  is_minute_45  \n",
       "0             1             0  \n",
       "1             1             0  \n",
       "2             1             0  \n",
       "3             1             0  \n",
       "4             1             0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Result: ')\n",
    "print(df_step1_dummies.shape)\n",
    "df_step1_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Build baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = train_test_split(df_step1_dummies, test_size = 0.75)\n",
    "X_test = test[test.columns[1:]]\n",
    "y_test = test[test.columns[0]]\n",
    "\n",
    "X_train = train[train.columns[1:]]\n",
    "y_train = train[train.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median absolute error: 30.80 (+/- 0.26)\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "scores = cross_val_score(regr, X_train, y_train, cv=5, scoring = 'neg_median_absolute_error')\n",
    "print(\"Median absolute error: %0.2f (+/- %0.2f)\" % (-scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median absolute error on test set: 30.86\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "error = median_absolute_error(y_test, y_pred)\n",
    "print('Median absolute error on test set: %.2f' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Improve baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear regression with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(train):\n",
    "    df = df_step1.iloc[train.index]\n",
    "\n",
    "    summary = df.groupby(['direction','route_interval']).agg({'time_diff_seconds': [np.mean, np.std]})\n",
    "    summary = summary.reset_index()\n",
    "    summary.columns = ['direction','route_interval','mean','std']\n",
    "    summary['min'] = summary['mean'] - 1.5 * summary['std'] \n",
    "    summary['max'] = summary['mean'] + 1.5 * summary['std'] \n",
    "\n",
    "    df = df.merge(summary, left_on = ['direction','route_interval'], \n",
    "             right_on = ['direction','route_interval'], how = 'left')\n",
    "    df['is_outlier'] = np.where ((df['time_diff_seconds'] > df['min']) & \\\n",
    "                (df['time_diff_seconds'] < df['max']), 0, 1)\n",
    "\n",
    "    not_outliers = df[df['is_outlier']==0].index\n",
    "    outliers_num = len(df[df['is_outlier']==1])\n",
    "    print('Number of outliers removed: ' + str(outliers_num))\n",
    "    \n",
    "    train = train.iloc[not_outliers]\n",
    "    return train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 7686\n"
     ]
    }
   ],
   "source": [
    "train_no_ouliters = remove_outliers(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median absolute error: 27.44 (+/- 0.21)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_no_ouliters[train_no_ouliters.columns[1:]]\n",
    "y_train = train_no_ouliters[train_no_ouliters.columns[0]]\n",
    "\n",
    "regr_improved = LinearRegression()\n",
    "regr_improved.fit(X_train, y_train)\n",
    "scores = cross_val_score(regr_improved, X_train, y_train, cv=5, scoring = 'neg_median_absolute_error')\n",
    "print(\"Median absolute error: %0.2f (+/- %0.2f)\" % (-scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median absolute error on test set: 29.28\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr_improved.predict(X_test)\n",
    "error = median_absolute_error(y_test, y_pred)\n",
    "print('Median absolute error on test set: %.2f' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting Regressor: Initial Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingRegressor(n_estimators = 300)\n",
    "\n",
    "param_grid = {\n",
    "              'learning_rate': [0.1, 0.05],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_leaf': [5, 9, 11]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=5 ..............\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=5, total=  34.1s\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=5, total=  34.4s\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=5, total=  32.6s\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=9, total=  32.6s\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=9, total=  29.4s\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=9, total=  29.8s\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=11, total=  34.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=11, total=  34.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=4, min_samples_leaf=11, total=  32.3s\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=5, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=5, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=5, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=9, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=9, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=9, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=11, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=6, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=11, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=6, min_samples_leaf=11, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=5, total= 2.0min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=5, total= 2.0min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=5, total= 2.0min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=9, total= 2.0min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=9 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=9, total= 2.0min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=9, total= 1.9min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=11, total= 1.8min\n",
      "[CV] learning_rate=0.1, max_depth=8, min_samples_leaf=11 .............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=11, total= 1.8min\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=5, total=  28.9s\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=5, total=  30.2s\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.1, max_depth=8, min_samples_leaf=11, total= 1.8min\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=5, total=  30.5s\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=9, total=  30.6s\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=9, total=  30.5s\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=9, total=  31.9s\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=11, total=  32.7s\n",
      "[CV] learning_rate=0.05, max_depth=4, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=11, total=  32.3s\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.05, max_depth=4, min_samples_leaf=11, total=  30.8s\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=5, total= 1.0min\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=5 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 19.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=5, total= 1.0min\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=5, total= 1.1min\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=9, total= 1.0min\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=9, total= 1.1min\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=9, total= 1.1min\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=11, total= 1.1min\n",
      "[CV] learning_rate=0.05, max_depth=6, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=11, total= 1.1min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.05, max_depth=6, min_samples_leaf=11, total= 1.0min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=5, total= 2.0min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=5 .............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=5, total= 1.9min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=5, total= 2.0min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=9, total= 1.9min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=9 .............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=9, total= 1.8min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=9, total= 1.8min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=11, total= 1.8min\n",
      "[CV] learning_rate=0.05, max_depth=8, min_samples_leaf=11 ............\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=11, total= 1.8min\n",
      "[CV]  learning_rate=0.05, max_depth=8, min_samples_leaf=11, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 32.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=300, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'learning_rate': [0.1, 0.05], 'max_depth': [4, 6, 8], 'min_samples_leaf': [5, 9, 11]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_median_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, scoring = 'neg_median_absolute_error',\n",
    "             n_jobs=2, cv=3, verbose=2 )\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Median absolute error: 19.93\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 11}\n"
     ]
    }
   ],
   "source": [
    "print('Best Median absolute error: %0.2f' % (-grid_search.best_score_))\n",
    "print('Best Parameters: ' + str(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting Regressor: Tuning min_sample_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = GradientBoostingRegressor(n_estimators = 300, \n",
    "                                 learning_rate = 0.1,\n",
    "                                 max_depth = 6)\n",
    "\n",
    "param_grid2 = {'min_samples_leaf': [11, 14, 17, 20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] min_samples_leaf=11 .............................................\n",
      "[CV] min_samples_leaf=11 .............................................\n",
      "[CV] .............................. min_samples_leaf=11, total= 1.0min\n",
      "[CV] min_samples_leaf=11 .............................................\n",
      "[CV] .............................. min_samples_leaf=11, total= 1.0min\n",
      "[CV] min_samples_leaf=14 .............................................\n",
      "[CV] .............................. min_samples_leaf=11, total= 1.0min\n",
      "[CV] min_samples_leaf=14 .............................................\n",
      "[CV] .............................. min_samples_leaf=14, total= 1.0min\n",
      "[CV] min_samples_leaf=14 .............................................\n",
      "[CV] .............................. min_samples_leaf=14, total= 1.0min\n",
      "[CV] min_samples_leaf=17 .............................................\n",
      "[CV] .............................. min_samples_leaf=14, total= 1.0min\n",
      "[CV] min_samples_leaf=17 .............................................\n",
      "[CV] .............................. min_samples_leaf=17, total= 1.1min\n",
      "[CV] min_samples_leaf=17 .............................................\n",
      "[CV] .............................. min_samples_leaf=17, total= 1.1min\n",
      "[CV] min_samples_leaf=20 .............................................\n",
      "[CV] .............................. min_samples_leaf=17, total= 1.0min\n",
      "[CV] min_samples_leaf=20 .............................................\n",
      "[CV] .............................. min_samples_leaf=20, total= 1.1min\n",
      "[CV] min_samples_leaf=20 .............................................\n",
      "[CV] .............................. min_samples_leaf=20, total= 1.0min\n",
      "[CV] .............................. min_samples_leaf=20, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=6, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=11,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=300, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'min_samples_leaf': [11, 14, 17, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_median_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2 = GridSearchCV(clf2, param_grid2, scoring = 'neg_median_absolute_error',\n",
    "             n_jobs=2, cv=3, verbose=2 )\n",
    "\n",
    "grid_search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Median absolute error: 19.93\n",
      "Best Parameters: {'min_samples_leaf': 11}\n"
     ]
    }
   ],
   "source": [
    "print('Best Median absolute error: %0.2f' % (-grid_search2.best_score_))\n",
    "print('Best Parameters: ' + str(grid_search2.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting Regressor: Final tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = GradientBoostingRegressor(n_estimators = 1000, \n",
    "                                 learning_rate = 0.1,\n",
    "                                 max_depth = 6,\n",
    "                                 min_samples_leaf = 11)\n",
    "\n",
    "param_grid3 = {'learning_rate': [0.1, 0.5, 0.02, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] learning_rate=0.1 ...............................................\n",
      "[CV] learning_rate=0.1 ...............................................\n",
      "[CV] ................................ learning_rate=0.1, total= 3.6min\n",
      "[CV] learning_rate=0.1 ...............................................\n",
      "[CV] ................................ learning_rate=0.1, total= 3.6min\n",
      "[CV] learning_rate=0.5 ...............................................\n",
      "[CV] ................................ learning_rate=0.1, total= 3.4min\n",
      "[CV] learning_rate=0.5 ...............................................\n",
      "[CV] ................................ learning_rate=0.5, total= 3.7min\n",
      "[CV] learning_rate=0.5 ...............................................\n",
      "[CV] ................................ learning_rate=0.5, total= 3.9min\n",
      "[CV] learning_rate=0.02 ..............................................\n",
      "[CV] ................................ learning_rate=0.5, total= 4.0min\n",
      "[CV] learning_rate=0.02 ..............................................\n",
      "[CV] ............................... learning_rate=0.02, total= 3.7min\n",
      "[CV] learning_rate=0.02 ..............................................\n",
      "[CV] ............................... learning_rate=0.02, total= 3.8min\n",
      "[CV] learning_rate=0.01 ..............................................\n",
      "[CV] ............................... learning_rate=0.02, total= 3.7min\n",
      "[CV] learning_rate=0.01 ..............................................\n",
      "[CV] ............................... learning_rate=0.01, total= 3.7min\n",
      "[CV] learning_rate=0.01 ..............................................\n",
      "[CV] ............................... learning_rate=0.01, total= 3.6min\n",
      "[CV] ............................... learning_rate=0.01, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed: 22.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=6, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=11,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1000, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'learning_rate': [0.1, 0.5, 0.02, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_median_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3 = GridSearchCV(clf3, param_grid3, scoring = 'neg_median_absolute_error',\n",
    "             n_jobs=2, cv=3, verbose=2 )\n",
    "\n",
    "grid_search3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Median absolute error: 20.08\n",
      "Best Parameters: {'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best Median absolute error: %0.2f' % (-grid_search3.best_score_))\n",
    "print('Best Parameters: ' + str(grid_search3.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=6, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=11,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1000, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_final = grid_search3.best_estimator_\n",
    "clf_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = clf_final\n",
    "joblib.dump(model, 'model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median absolute error on test set: 21.77\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_final.predict(X_test)\n",
    "error = median_absolute_error(y_test, y_pred)\n",
    "print('Median absolute error on test set: %.2f' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = df_step0.iloc[X_test.index]\n",
    "df_evaluation = df_evaluation[['direction','route_interval', 'time_diff_seconds']]\n",
    "df_evaluation['predictions'] = y_pred\n",
    "df_evaluation['error'] = np.abs(df_evaluation['predictions'] - df_evaluation['time_diff_seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary = df_evaluation.groupby(['direction','route_interval']).agg({'error' : ['count', np.median]})\n",
    "error_summary = error_summary.reset_index()\n",
    "error_summary.columns = ['direction','route_interval','n','median_error']\n",
    "error_summary['error_type'] = np.where(error_summary['median_error'] > error*1.25, 'high',\n",
    "                              np.where(error_summary['median_error'] < error*0.75, 'low', 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>route_interval</th>\n",
       "      <th>n</th>\n",
       "      <th>median_error</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>#26_#27</td>\n",
       "      <td>807</td>\n",
       "      <td>108.142714</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>#27_#28</td>\n",
       "      <td>924</td>\n",
       "      <td>88.727332</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>#18_#19</td>\n",
       "      <td>932</td>\n",
       "      <td>43.556659</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#02_#03</td>\n",
       "      <td>657</td>\n",
       "      <td>33.289124</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>#12_#13</td>\n",
       "      <td>745</td>\n",
       "      <td>31.618724</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>#10_#11</td>\n",
       "      <td>748</td>\n",
       "      <td>30.619026</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>#15_#16</td>\n",
       "      <td>614</td>\n",
       "      <td>30.306155</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>#13_#14</td>\n",
       "      <td>452</td>\n",
       "      <td>29.956692</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>#17_#18</td>\n",
       "      <td>940</td>\n",
       "      <td>29.701877</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>#00_#01</td>\n",
       "      <td>1035</td>\n",
       "      <td>28.627297</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>#04_#05</td>\n",
       "      <td>935</td>\n",
       "      <td>28.508142</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>#16_#17</td>\n",
       "      <td>912</td>\n",
       "      <td>28.413712</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>#25_#26</td>\n",
       "      <td>834</td>\n",
       "      <td>28.261078</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>#05_#06</td>\n",
       "      <td>858</td>\n",
       "      <td>28.031559</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>#11_#12</td>\n",
       "      <td>806</td>\n",
       "      <td>27.417206</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    direction route_interval     n  median_error error_type\n",
       "25          0        #26_#27   807    108.142714       high\n",
       "53          1        #27_#28   924     88.727332       high\n",
       "44          1        #18_#19   932     43.556659       high\n",
       "1           0        #02_#03   657     33.289124       high\n",
       "11          0        #12_#13   745     31.618724       high\n",
       "9           0        #10_#11   748     30.619026       high\n",
       "14          0        #15_#16   614     30.306155       high\n",
       "39          1        #13_#14   452     29.956692       high\n",
       "43          1        #17_#18   940     29.701877       high\n",
       "26          1        #00_#01  1035     28.627297       high\n",
       "30          1        #04_#05   935     28.508142       high\n",
       "42          1        #16_#17   912     28.413712       high\n",
       "51          1        #25_#26   834     28.261078       high\n",
       "31          1        #05_#06   858     28.031559       high\n",
       "10          0        #11_#12   806     27.417206       high"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_summary[error_summary['error_type'] == 'high'].sort_values(by = 'median_error', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>route_interval</th>\n",
       "      <th>n</th>\n",
       "      <th>median_error</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>#21_#22</td>\n",
       "      <td>418</td>\n",
       "      <td>16.309283</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>#01_#02</td>\n",
       "      <td>974</td>\n",
       "      <td>16.048940</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>#10_#11</td>\n",
       "      <td>634</td>\n",
       "      <td>15.712757</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>#23_#24</td>\n",
       "      <td>688</td>\n",
       "      <td>15.638464</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>#12_#13</td>\n",
       "      <td>417</td>\n",
       "      <td>15.081569</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>#19_#20</td>\n",
       "      <td>543</td>\n",
       "      <td>14.772386</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>#20_#21</td>\n",
       "      <td>571</td>\n",
       "      <td>13.429593</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>#25_#26</td>\n",
       "      <td>749</td>\n",
       "      <td>13.368453</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>#23_#24</td>\n",
       "      <td>657</td>\n",
       "      <td>13.253535</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#04_#05</td>\n",
       "      <td>566</td>\n",
       "      <td>12.204376</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>#17_#18</td>\n",
       "      <td>349</td>\n",
       "      <td>12.052359</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>#11_#12</td>\n",
       "      <td>585</td>\n",
       "      <td>10.858193</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>#08_#09</td>\n",
       "      <td>50</td>\n",
       "      <td>8.884087</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>#07_#08</td>\n",
       "      <td>45</td>\n",
       "      <td>7.854191</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    direction route_interval    n  median_error error_type\n",
       "20          0        #21_#22  418     16.309283        low\n",
       "27          1        #01_#02  974     16.048940        low\n",
       "36          1        #10_#11  634     15.712757        low\n",
       "49          1        #23_#24  688     15.638464        low\n",
       "38          1        #12_#13  417     15.081569        low\n",
       "18          0        #19_#20  543     14.772386        low\n",
       "19          0        #20_#21  571     13.429593        low\n",
       "24          0        #25_#26  749     13.368453        low\n",
       "22          0        #23_#24  657     13.253535        low\n",
       "3           0        #04_#05  566     12.204376        low\n",
       "16          0        #17_#18  349     12.052359        low\n",
       "37          1        #11_#12  585     10.858193        low\n",
       "34          1        #08_#09   50      8.884087        low\n",
       "33          1        #07_#08   45      7.854191        low"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_summary[error_summary['error_type'] == 'low'].sort_values(by = 'median_error', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
